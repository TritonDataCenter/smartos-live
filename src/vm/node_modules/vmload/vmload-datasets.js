/*
 * CDDL HEADER START
 *
 * The contents of this file are subject to the terms of the
 * Common Development and Distribution License, Version 1.0 only
 * (the "License").  You may not use this file except in compliance
 * with the License.
 *
 * You can obtain a copy of the license at http://smartos.org/CDDL
 *
 * See the License for the specific language governing permissions
 * and limitations under the License.
 *
 * When distributing Covered Code, include this CDDL HEADER in each
 * file.
 *
 * If applicable, add the following below this CDDL HEADER, with the
 * fields enclosed by brackets "[]" replaced with your own identifying
 * information: Portions Copyright [yyyy] [name of copyright owner]
 *
 * CDDL HEADER END
 *
 * Copyright (c) 2014, Joyent, Inc. All rights reserved.
 *
 */

var assert = require('assert');
var async = require('/usr/node/node_modules/async');
var EventEmitter = require('events').EventEmitter;
var props = require('/usr/vm/node_modules/props');
var spawn = require('child_process').spawn;
var utils = require('utils');

var VMOBJ_ZFS_DEPENDENCIES = props.VMOBJ_ZFS_DEPENDENCIES;
var ZFS_FIELDS = props.ZFS_FIELDS;
var ZFS_TYPES = props.ZFS_TYPES;

// utils
var trim = utils.trim;

// zfs_list_queue variables for the serialization of 'zfs list' calls
var zfs_list_in_progress = {};
var zfs_list_queue;

function addDatasetResult(fields, types, results, line, log)
{
    var dataset;
    var field;
    var lfields;
    var obj;
    var snapparts;
    var snapobj;

    line = trim(line);

    if (line.length === 0) {
        return;
    }

    lfields = line.split(/\s+/);

    if (lfields.length !== fields.length) {
        return;
    }

    obj = {};

    for (field in fields) {
        obj[fields[field]] = lfields[field];
    }

    cleanDatasetObject(obj);

    if (types.indexOf('snapshot') !== -1 && obj.type === 'snapshot') {
        /*
         * For snapshots we store the snapname and optionally creation keyed by
         * dataset name So that we can include the list of snapshots for a
         * dataset on a VM.
         */
        snapparts = obj.name.split('@');
        assert.equal(snapparts.length, 2);
        dataset = snapparts[0];
        snapobj = {snapname: snapparts[1], dataset: dataset};
        if (!results.snapshots.hasOwnProperty(dataset)) {
            results.snapshots[dataset] = [];
        }
        if (obj.hasOwnProperty('creation')) {
            snapobj.created_at = obj.creation;
        }
        if (obj.hasOwnProperty('userrefs') && obj.userrefs > 0) {
            snapobj.userrefs = obj.userrefs;
        }
        results.snapshots[dataset].push(snapobj);
    }

    results.datasets[obj.name] = obj;

    /*
     * snapshots don't have mountpoint that we care about and we don't count
     * 'none' as a mountpoint. If we otherwise have a mountpoint that looks like
     * a path, we add a pointer from that to the dataset name.
     */
    if (obj.type !== 'snapshot' && obj.mountpoint[0] === '/') {
        /*
         * For zoned filesystems (delegated datasets) we don't use mountpoint as
         * this can be changed from within the zone and is therefore not
         * reliable. Also, when a delegated dataset is assigned but the zone's
         * not been booted, the delegated dataset will not have the 'zoned'
         * property.  So we also check if the name ends in /data.
         */
        if (obj.hasOwnProperty('zoned') && obj.zoned === 'on') {
            // don't add zoned datasets to mountpoints
            /*jsl:pass*/
        } else if (obj.name.split('/')[2] === 'data') {
            // name is /data, skip
            /*jsl:pass*/
        } else {
            // here we have what looks like a normal non-zoned dataset that's
            // probably a zoneroot, add to mountpoints mapping.
            results.mountpoints[obj.mountpoint] = obj.name;
        }
    }
}

function cleanDatasetObject(obj)
{
    var number_fields = [
        'avail',
        'available',
        'copies',
        'creation',
        'filesystem_limit',
        'quota',
        'recsize',
        'recordsize',
        'refer',
        'referenced',
        'refquota',
        'refreserv',
        'refreservation',
        'reserv',
        'reservation',
        'snapshot_limit',
        'usedbychildren',
        'usedbydataset',
        'usedbyrefreservation',
        'usedbysnapshots',
        'used',
        'userrefs',
        'utf8only',
        'version',
        'volblock',
        'volblocksize',
        'volsize',
        'written'
    ];

    // We should always have mountpoint, dataset and type because we force them
    // to be included in zfsList()
    assert(obj.hasOwnProperty('mountpoint'), 'cleanDatasetObject('
        + JSON.stringify(obj) + '): missing mountpoint');
    assert(obj.hasOwnProperty('name'), 'cleanDatasetObject('
        + JSON.stringify(obj) + '): missing name');
    assert(obj.hasOwnProperty('type'), 'cleanDatasetObject('
        + JSON.stringify(obj) + '): missing type');

    // convert numeric fields to proper numbers
    number_fields.forEach(function (field) {
        if (obj.hasOwnProperty(field) && obj[field] !== '-') {
            obj[field] = Number(obj[field]);
        }
    });

    if (obj.type === 'volume') {
        obj.mountpoint = '/dev/zvol/rdsk/' + obj.name;
    } else if (obj.mountpoint === '-' || obj.mountpoint === 'legacy') {
        obj.mountpoint = '/' + obj.name;
    }
}

function getDatasets(uuid, obj, options, callback)
{
    var fields;
    var log;
    var _options = {};
    var zfs_fields = [];
    var zfs_types = [];
    var result, listEverything, parents;

    fields = options.fields;
    log = options.log;
    assert(log, 'no logger passed to getDatasets()');

    function addField(name) {
        if (zfs_fields.indexOf(name) === -1) {
            zfs_fields.push(name);
        }
    }

    function addType(name) {
        if (zfs_types.indexOf(name) === -1) {
            zfs_types.push(name);
        }
    }

    if (!fields || fields.length < 1) {
        // Default to grabbing everything we might possibly need.
        zfs_fields = ZFS_FIELDS;
        zfs_types = ZFS_TYPES;
    } else {
        Object.keys(VMOBJ_ZFS_DEPENDENCIES).forEach(function (key) {
            var dep = VMOBJ_ZFS_DEPENDENCIES[key];

            if (fields.indexOf(key) !== -1) {
                /*
                 * The vmobj field is in the list of those we want in output, so
                 * add the list of zfs fields and types we need to build that
                 * into the final vmobj.
                 */
                if (dep.hasOwnProperty('fields')) {
                    dep.fields.forEach(function (field) {
                        addField(field);
                    });
                }
                if (dep.hasOwnProperty('types')) {
                    dep.types.forEach(function (type) {
                        addType(type);
                    });
                }
            }
        });
    }

    if (zfs_fields.length > 0) {
        // we have some fields so we need to zfs, make sure we have name,
        // mountpoint and type which we always need if we get anything.
        addField('mountpoint');
        addField('name');
        addField('type');

        if (zfs_types.indexOf('filesystem') !== -1) {
            // to differentiate between delegated and root filesystems
            addField('zoned');
        }
    } else {
        log.debug('no need to call zfs');
        callback(null, {
            datasets: {},
            mountpoints: {},
            snapshots: {}
        });
        return;
    }

    /*
     * In case we have to do multiple zfs list commands, we want to add their
     * results together in one place. Create an empty results object and give
     * it to each of them to add their lines to.
     */
    result = {
        datasets: {},
        mountpoints: {},
        snapshots: {}
    };
    /*
     * Note that 'fields' here is the *zfs* fields and not the VM object
     * fields. That's why we can't just pass the options we were given through
     * and instead build a new one.
     */
    _options = {
        fields: zfs_fields,
        log: log,
        types: zfs_types,
        results: result
    };

    listEverything = false;
    parents = [];

    /*
     * The zonepath property is always of the form '/' + zfs_filesystem,
     * as this is how it is built in createZone().
     */
    if (obj.zonepath) {
        assert.strictEqual(obj.zonepath[0], '/');
        parents.push(obj.zonepath.slice(1));

    } else {
        /*
         * If we don't have one we're listing all VMs and need to fetch
         * everything anyway.
         */
        listEverything = true;
    }

    if (obj.datasets) {
        obj.datasets.forEach(function (ds) {
            parents.push(ds);
        });
    }

    if (obj.disks) {
        obj.disks.forEach(function (ds) {
            /*
             * If we have even one disk that we can't recognise as a zvol,
             * then give up and "zfs list" everything on the system.
             */
            var m = ds.path.match(/^\/dev\/zvol\/r?dsk\/(.+)$/);
            if (m && m[1]) {
                parents.push(m[1]);
            } else {
                listEverything = true;
            }
        });
    }

    if (options.hasOwnProperty('spawnZfs')) {
        _options.spawnZfs = options.spawnZfs;
    }

    if (listEverything) {
        getZfsList(_options, callback);

    } else {
        async.eachSeries(parents, function (parent, cb) {
            _options.parent = parent;
            getZfsList(_options, cb);
        }, function (err) {
            if (err) {
                callback(err);
                return;
            }
            callback(null, result);
        });
    }
}

function getZfsList(options, callback) {
    var fields = options.fields;
    var log = options.log;
    var sorted_fields;
    var sorted_types;
    var task;
    var types = options.types;

    sorted_fields = fields.slice().sort();
    sorted_types = types.slice().sort();

    // any options we need in zfsList() need to be passed through here.
    task = {
        fields: sorted_fields,
        log: log,
        types: sorted_types
    };
    if (options.hasOwnProperty('spawnZfs')) {
        task.spawnZfs = options.spawnZfs;
    }
    if (options.hasOwnProperty('parent')) {
        task.parent = options.parent;
    }
    if (options.hasOwnProperty('results')) {
        task.results = options.results;
    }

    try {
        zfs_list_in_progress[task].on('result', callback);
    } catch (e) {
        if ((e instanceof TypeError)
            && (!zfs_list_in_progress.hasOwnProperty(task)
            || !zfs_list_in_progress[task].hasOwnProperty('on'))) {

            zfs_list_in_progress[task] = new EventEmitter();
            zfs_list_in_progress[task].on('result', callback);
            zfs_list_in_progress[task].setMaxListeners(0);
            zfs_list_queue.push(task);

            // callback() will get called when 'result' is emitted.
        } else {
            callback(e);
        }
    }
}

function makeEnv() {
    var env = {};
    var names = Object.keys(process.env);
    var name;
    var i;

    for (i = 0; i < names.length; i++) {
        name = names[i];

        if (name === 'LANG' || name.match(/^LC_/)) {
            /*
             * Do not copy any locale variables into the child environment.
             * See environ(5) for more information about what these variables
             * mean.
             */
            continue;
        }

        env[name] = process.env[name];
    }

    /*
     * Force the POSIX locale so that error messages are presented
     * consistently.
     */
    env.LANG = env.LC_ALL = 'C';

    return (env);
}

function zfs(options, cmd, args, lineHandler, callback)
{
    var buffer = '';
    var errbuffer = '';
    var line_count = 0;
    var lines;
    var log = options.log;
    var zfs_child;
    var gotNotExist = false;

    log.debug({cmdline: cmd + ' ' + args.join(' ')}, 'executing zfs');
    zfs_child = spawn(cmd, args, {
        stdio: 'pipe',
        env: makeEnv()
    });
    log.debug('zfs[' + zfs_child.pid + '] running');

    zfs_child.stdout.on('data', function (data) {
        var line;

        buffer += data.toString();
        lines = buffer.split('\n');
        while (lines.length > 1) {
            line = lines.shift();
            line_count++;

            // Add this line to results
            lineHandler(line);
        }
        buffer = lines.pop();
    });

    // we don't expect data on stderr, so treat as a warning
    zfs_child.stderr.on('data', function (data) {
        var elines, line;
        errbuffer += data.toString();
        elines = errbuffer.split('\n');
        while (elines.length > 1) {
            line = elines.shift();
            if (line.indexOf('dataset does not exist') !== -1) {
                gotNotExist = true;
            }
            log.warn({stderr: line}, 'zfs[' + zfs_child.pid + '] wrote '
                + 'output to stderr.');
        }
        errbuffer = elines[0];
    });

    // doesn't take input.
    zfs_child.stdin.end();

    zfs_child.on('close', function (code) {
        /* In case there's a partial line leftover with no newline. */
        if (errbuffer.length > 0) {
            log.warn({stderr: errbuffer}, 'zfs[' + zfs_child.pid + '] wrote '
                + 'output to stderr.');
        }

        log.debug('zfs[' + zfs_child.pid + '] exited with code: ' + code
            + ' (' + line_count + ' lines to stdout)');
        if (code === 0) {
            callback();
        } else if (code === 1 && options.hasOwnProperty('parent')
            && gotNotExist) {
            /*
             * When we're recursively listing under a parent dataset, and
             * that dataset doesn't exist yet, emulate the behaviour of
             * a filtered "list everything" -- ie, return ok
             */
            callback();
        } else {
            callback(new Error('zfs exited prematurely with code: ' + code));
        }
    });
}

/*
 * Arguments:
 *
 * 'options'  - an object containing:
 *     'fields'   - an array of fields as in the zfs(1m) man page (required)
 *     'types'    - one or more of: filesystem, snapshot, volume. (required)
 *     'log'      - a bunyan logger object. (required)
 *     'spawnZfs' - a function(options, cmd, args, lineHandler, callbackHandler)
 * 'callback' - will be called with (err, results)
 *
 * On failure: callback's err will be an Error object, ignore results.
 * On success: callback's results is an object with one or more members of:
 *
 *     results.datasets
 *
 *         keyed by dataset name containing the values for the requested fields.
 *
 *         Eg: results.datasets['zones/cores'] === { name: 'zones/cores', ... }
 *
 *     results.mountpoints
 *
 *         keyed by mountpoint with value being dataset name.
 *
 *         Eg: results.mountpoints['/zones/cores'] === 'zones/cores'
 *
 *     results.snapshots
 *
 *         keyed by dataset with value being array of snapname and created_at.
 *
 *         Eg: results.snapshots['/zones/cores'] === ['snap1', ...]
 *
 * For non-zoned filesystem datasets (these should be the zoneroot datasets),
 * you can use mountpoint which comes from zoneadm's "cheap" info and use that
 * to get to the dataset and from datasets[dataset] get the info.
 *
 * For volumes (KVM VM's disks) you can also use mountpoint as we'll set that
 * to the block device path and that's available from the devices section of
 * the zoneconfig.
 *
 * For zoned filesystems (delegated datasets) use the dataset name, as the
 * mountpoint can be changed from within the zone.
 *
 */
function zfsList(options, callback) {
    var args;
    var cmd = '/usr/sbin/zfs';
    var fields = options.fields;
    var log = options.log;
    var req_fields = ['mountpoint', 'name', 'type'];
    var results;
    var spawnZfs;
    var types = options.types;

    assert(Array.isArray(types), '"types" must be array, is: '
        + typeof (types));
    assert(Array.isArray(fields), '"fields" must be array, is: '
        + typeof (fields));
    assert(log, 'no logger passed to zfsList()');

    results = options.results;
    if (results === undefined || typeof (results) !== 'object'
        || typeof (results.datasets) !== 'object') {

        results = {
            datasets: {},
            mountpoints: {},
            snapshots: {}
        };
    }

    // Called when the `zfs` command or its mock completes
    function callbackHandler(err) {
        if (err) {
            callback(err);
        } else {
            callback(null, results);
        }
    }

    // Called for each line output by `zfs` or its mock
    function lineHandler(line) {
        // Add this line to results
        addDatasetResult(fields, types, results, line, log);
    }

    // add any missing required fields
    req_fields.forEach(function (field) {
        if (fields.indexOf(field) === -1) {
            fields.push(field);
        }
    });

    args = ['list', '-H', '-p', '-t', types.join(','), '-o', fields.join(',')];
    if (options.hasOwnProperty('parent')) {
        args.push('-r');
        args.push(options.parent);
    }

    /*
     * Allow mocking out the zfs call. If options includes a 'spawnZfs' function
     * that's used instead of the zfs() function defined in this file. It must:
     *
     *  - have prototype: fn(options, cmd, args, lineHandler, callbackHandler)
     *  - call lineHandler(line) for each (virtual) line of zfs output
     *  - call callbackHandler(err) on completion (err passed only on failure)
     *
     * it may also use options.log to log messages for the operator.
     */
    spawnZfs = zfs;
    if (options.hasOwnProperty('spawnZfs')) {
        spawnZfs = options.spawnZfs;
    }

    /*
     * callbackHandler() will be called on completion and that's what calls
     * _our_ callback.
     */
    spawnZfs(options, cmd, args, lineHandler, callbackHandler);
}

/*
 * This queue is used to handle zfs list requests. We do this because of OS-1834
 * in order to only run one 'zfs list' at a time. If we need to get data from
 * 'zfs list', the parameters we want to list are pushed onto this queue. If a
 * list is already running with the same parameters, we'll return the output
 * from that one when it completes to all the consumers. If there's not one
 * running, or the parameters are different, this set of parameters will be
 * pushed onto the tail of the queue. The queue is processed serially so long
 * as there are active requests.
 */
zfs_list_queue = async.queue(function (task, callback) {

    var log = task.log;
    var options = {};
    var started = Date.now(0);

    options = {
        fields: task.fields,
        log: log,
        types: task.types
    };
    if (task.hasOwnProperty('spawnZfs')) {
        options.spawnZfs = task.spawnZfs;
    }
    if (task.hasOwnProperty('parent')) {
        options.parent = task.parent;
    }
    if (task.hasOwnProperty('results')) {
        options.results = task.results;
    }

    zfsList(options, function (err, data) {
        var emitter = zfs_list_in_progress[task];

        delete zfs_list_in_progress[task];
        emitter.emit('result', err, data);
        emitter.removeAllListeners('result');

        log.debug('zfs list took ' + (Date.now(0) - started) + ' ms');
        callback();
    });

}, 1);

zfs_list_queue.drain = function () {
    // XXX we'd like to log here, but there's no logger in our scope.
    // log.trace('zfs_list_queue is empty');
};

module.exports = {
    getDatasets: getDatasets
};
