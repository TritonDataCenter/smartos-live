/*

# ZFS Library

This is an alternative library for managing ZFS using spawned
processes. It remains less than ideal.

Sizes are normalized in MB (MegaBytes or 1024*1024)

### Implemented:
* List Datasets
* Get a single dataset
* Receive Dataset (from a readable stream)
* Send Dataset
* Get a recursive list of datasets
* Take a Snapshot of a Dataset
* Delete a dataset (option recuursively)
* Get a dataset and its children as an array

### To Implement:

* Rollback a Snapshot

*/

var path = require('path');
var fs = require('fs');
var spawn = require('child_process').spawn;
var exec = require('child_process').exec;
var assert = require('assert');

var ZFS='/usr/sbin/zfs';
var ZPOOL='/usr/sbin/zpool';

var ZPOOL_PROPERTIES = [
  'name',
  'size',
  'alloc',
  'free',
  'cap',
  'dedup',
  'health'
];

var QUERY_PROPERTIES = [
  'name',
  'type',
  'origin',
  'creation',
  'used',
  'available',
  'referenced',
  'quota',
  'usedbydataset',
  'usedbysnapshots',
  'usedbychildren',
  'volsize',
  'volblocksize',
  'dsadm:uuid',
  'dsadm:urn'
];

var VOL_PROPERTIES = [
  'name',
  'type',
  'origin',
  'creation',
  'used',
  'available',
  'referenced',
  'usedbydataset',
  'usedbysnapshots',
  'usedbychildren',
  'volsize',
  'volblocksize',
  'dsadm:uuid',
  'dsadm:urn'
];

var SNAP_PROPERTIES = [
  'name',
  'type',
  'creation',
  'used'
];

var FS_PROPERTIES = [
  'name',
  'type',
  'origin',
  'creation',
  'used',
  'available',
  'referenced',
  'quota',
  'usedbydataset',
  'usedbysnapshots',
  'usedbychildren',
  'dsadm:uuid',
  'dsadm:urn'
];

var ERR_LIST    = 10;
var ERR_SET     = 11;
var ERR_RECV    = 12;
var ERR_GET     = 13;
var ERR_EXIST   = 20;
var ERR_RENAME  = 21;
var ERR_SNAP    = 22;
var ERR_DESTROY = 23;

var newError = function(code, message) {
  assert.ok(code);
  assert.ok(message);
  return JSON.stringify({error: {code: code, message: message}});
};

function toMB(value) {
  return Math.ceil(value / 1048676); // 1024*1024
}

function toMiB(value) {
  return Math.ceil(value / 1000000); // 1000*1000
}

var _formatPoolProperty = function(prop, val) {
  assert.ok(prop);
  assert.ok(val);
 
  if (val === "-") {
    return [prop, null];
  }

  switch (prop) {
    case "size":
      val = toMB(val);
      break;
    case "free":
      val = toMB(val);
      break;
    case "alloc":
      val = toMB(val);
      break;
  }
  return [prop, val];
};

var _formatRecord = function(record) {
  assert.ok(record);

  var result;

  var format = function(record, properties) {
    assert.ok(record);
    assert.ok(properties);

    var r = {};
    for (var i in properties) {
      if (properties.hasOwnProperty(i)) {
        var p = properties[i];
        var v = record[p];
        r[p] = _formatProperty(p, v)[1];
      }
    }
    return r;
  };

  switch(record.type) {
    case "volume":
      result = format(record, VOL_PROPERTIES);
      break;
    case "snapshot":
      result = format(record, SNAP_PROPERTIES);
      break;
    case "filesystem":
      result = format(record, FS_PROPERTIES);
      break;
  }

  return result;
};

var _formatProperty = function(prop, val) {
  assert.ok(prop);
  assert.ok(val);

  if (val === "-") {
    return [prop, null];
  }

  switch (prop) {
    case "sdc:dataset":
      if (val === null) {
        val = false;
      } else {
        val = true;
      }
      break;
    case "used":
      val = toMB(val);
      break;
    case "available":
      val = toMB(val);
      break;
    case "referenced":
      val = toMB(val);
      break;
    case "quota":
      val = toMB(val);
      break;
    case "usedbydataset":
      val = toMB(val);
      break;
    case "usedbysnapshots":
      val = toMB(val);
      break;
    case "usedbychildren":
      val = toMB(val);
      break;
    case "volsize":
      val = toMB(val);
      break;
    case "volblocksize":
      val = parseInt(val, 10);
      break;
    case "creation":
      var d = (val * 1000);
      val = new Date(d).toJSON();
      break;
  }
  return [prop, val];
};

var setFilter = {
  dataset: function(ele, idx, arr) {
    return (ele['dsadm:uuid']);
  },
  origin: function(ele, idx, arr) {
    return (ele.origin);
  },
  snapshot: function(ele, idx, arr) {
    return (ele.type === 'snapshot');
  },
  volume: function(ele, idx, arr) {
    return (ele.type === 'volume');
  },
  filesystem: function(ele, idx, arr) {
    return (ele.type === 'filesystem');
  }

};

var get = function(name, callback) {
  assert.ok(name);
  assert.ok(callback);

  var data = '';
  var error = null;
  var args = ['get', '-pH', '-o', 'property,value'];
  args.push(QUERY_PROPERTIES.join(','));
  args.push(name);

  var zfs = spawn(ZFS, args);

  var parseData = function() {
    var dataset = {};
    var line, prop, val;
    var lines = data.split(/\n/);
    for (var i=0; i<lines.length; i++) {
      line = lines[i].split(/\t/);
      prop = line[0];
      val = line[1];

      dataset[prop] = val;

    }
    callback(error, _formatRecord(dataset));
  };

  zfs.stdout.on('data', function(chunk) {
    data = data + chunk.toString();
  });

  zfs.on('exit', function(code, signal) {
    parseData();
  });
  
};

var getRecursive = function(name, callback) {
  assert.ok(name);
  assert.ok(callback);

  var data = '';
  var error = null;
  var args = ['get', '-rpH', '-o', 'name,property,value'];
  args.push(QUERY_PROPERTIES.join(','));
  args.push(name);
  
  var zfs = spawn(ZFS, args);

  var parseData = function() {
    var old, name, prop, val;
    var datasets = [];
    var dataset = {};
    var lines = data.split(/\n/);
    
    for (var i=0; i<lines.length; i++) {
      var line = lines[i].split(/\t/);
      if (line.length === 1) {
        datasets.push(_formatRecord(dataset));
        break;
      }
      
      name = line[0];
      prop = line[1];
      val = line[2];

      if (old === name) {
        dataset[prop] = val;
      }
      else {
        old = name;
        if (dataset.name) {
          datasets.push(_formatRecord(dataset));
        }
        dataset = {name: name};
        dataset[prop] = val;
      }
    }
    callback(error, datasets);
  };
  
  zfs.stdout.on('data', function(chunk) {
    data = data + chunk.toString();
  });

  zfs.on('exit', function(code, signal) {
     parseData();
  });
  
};

var getClones = function(name, callback) {
  assert.ok(name);
  assert.ok(callback);

  list(null, function(err, datasets) {
    if (err) {
      return callback(err, null);
    }
    var clones = [];
    for (var i=0; i<datasets.length; i++) {
      // console.log(datasets[i].name);
      if (datasets[i].origin === name) {
        clones.push(datasets[i]);
      }
    }
   callback(err, clones);
  });
   
};

var getSnapshots = function(name, callback) {
  assert.ok(name);
  assert.ok(callback);

  getRecursive(name, function(err, datasets) {
    if (err) {
      return callback(err, null);
    }
    datasets.shift(); // first result is the actual dataset

    callback(null, datasets);
  });
};

// returns a full list of all datasets
var list = function(options, callback) {
  var _options = {
    type: 'all' // valid are snapshot, vol,
  };

  var data = '';
  var error = null;
  var args = ['list', '-rpH', '-t', _options.type, '-o'];
  args.push(QUERY_PROPERTIES.join(','));
  
  var zfs = spawn(ZFS, args);
  
  var parseData = function() {
    var datasets = [];
    var lines = data.split(/\n/);
    for (var i=0; i<lines.length; i++) {
      var line = lines[i].split(/\t/);
      var dataset = {};
      
      if (line.length === 1) {
        continue;
      }
      
      for (var p=0; p<QUERY_PROPERTIES.length; p++) {
        var val = line[p];
        var prop = QUERY_PROPERTIES[p];
        dataset[prop] = val ;
      }

      datasets.push(_formatRecord(dataset));
    }
    callback(error, datasets);
  };

  zfs.stdout.on('data', function(chunk) {
    data = data + chunk.toString();
  });

  zfs.stderr.on('data', function(chunk) {
    callback(newError(ERR_LIST, "error listing datasets"), null);
  });
  
  zfs.on('exit', function(code, signal) {
    parseData();
  });

};


var snapshot = function(name, options, callback) {
  assert.ok(name);
  var _options = {
    recursive: false,  // bool
    property: null     // must be an array
  };
 
  var error = null;
  var args = ['snapshot'];

  if (_options.recursive === true) {
    args.push('-r');
  }
  if (_options.property) {
    args.push(_options.property[0] + '=' + _options.property[1]);
  }

  args.push(name);

  var zfs = spawn(ZFS, args);
 
  zfs.stderr.on('data', function(chunk) {
    error = newError(ERR_SNAP, "error taking snapshot" + chunk);
  });
  
  zfs.on('exit', function(code, signal) {
    callback(error);
  });
};

var destroy = function(name, options, callback) {
  assert.ok(name);
  
  options = options || { recursive: false };

  var error = null;
  var args = ['destroy'];

  if (options.recursive === true) {
    args.push('-r');
  }
  args.push(name);

  var zfs = spawn(ZFS, args);

  zfs.stderr.on('data', function(chunk) {
    error = newError(ERR_DESTROY, "error destroying snapshot" + chunk);
  });
  
  zfs.on('exit', function(code, signal) {
    callback(error);
  });

};

var setProp = function(name, property, value, callback) {
  assert.ok(name);
  assert.ok(property);
  assert.ok(value);
  assert.ok(callback);

  var args = ['set'];
  args.push(property + '=' + value);
  args.push(name);

  var err;
  var zfs = spawn(ZFS, args);

  zfs.on('exit', function(code, signal) {
    callback(err);
  });

  zfs.stderr.on('data', function(chunk) {
    err = newError(ERR_SET, "error setting property" + chunk);
  });

};

var rename = function(name, newname, callback) {
  assert.ok(name);
  assert.ok(newname);

  var args = ['rename', name, newname];
  var zfs = spawn(ZFS, args);

  zfs.on('exit', function(code, signal) {
    if (callback) {
      callback(null);
    }
  });

  zfs.stderr.on('data', function(chunk) {
    if (callback) {
      callback(newError(ERR_RENAME, "error renaming dataset"));
    }
  });
 
};

var receiveStream = function(name, readStream, callback) {
  assert.ok(name);
  assert.ok(readStream);
  assert.ok(callback);

  var args = ['recv']; // add '-n' when testing
  var _name = name; // + '-partial';
  args.push(_name);

  var zfs = spawn(ZFS, args);

  readStream.pipe(zfs.stdin); // ;)

  zfs.on('exit', function(code, signal) {
    return callback();
  });

  zfs.stderr.on('data', function(chunk) {
    callback(newError(ERR_RECV, "error receiving dataset"));
  });

};

var spawnReceiveStream = function(name) {
  assert.ok(name);

  var args = ['recv'];
  var _name = name; // + '-partial';
  args.push(_name);

  var zfs = spawn(ZFS, args);

  return zfs; // cheating / felony
  
};

var sendStream = function(name, writeStream, callback) {
  assert.ok(name);
  assert.ok(writeStream);
  assert.ok(callback);

  var args = ['send'];
  args.push(name);
  
  var zfs = spawn(ZFS, args);
  
  zfs.stdout.pipe(writeStream);
  
  zfs.on('exit', function(code, signal) {
    callback(null);
  });

  zfs.stderr.on('data', function(chunk) {
    callback(newError(ERR_SEND, "error sending dataset"));
  });

};

var getPool = function(name, callback) {
  assert.ok(name);
  assert.ok(callback);

  var pool = {};
 
  listPool(null, function(err, pools) {
    for (var i=0; i<pools.length; i++) {
      if (pools[i].name === name) {
        pool = pools[i];
      }
    }
    callback(err, pool);
  });
};

var listPool = function(options, callback) {
  assert.ok(callback);
     
  var args = ['list', '-pH', '-o'];
  args.push(ZPOOL_PROPERTIES.join(','));
  
  var pools = [];
  var zpool = spawn(ZPOOL, args);
  
  zpool.stdout.on('data', function(chunk) {
    var lines = chunk.toString().split(/\n/);
    for (var i=0; i<lines.length; i++) {
      var line = lines[i].split(/\t/);
      var pool = {};
      
      if (line.length === 1) {
        continue;
      }
      
      for (var p=0; p<ZPOOL_PROPERTIES.length; p++) {
        var val = line[p];
        var prop = ZPOOL_PROPERTIES[p];
      
        val = _formatPoolProperty(prop, val)[1];
      
        pool[prop] = val;
      }
      
      pools.push(pool);
    }
  });

  zpool.on('exit', function(code, signal) {
    callback(null, pools);
  });
  
};

module.exports = {
  list: list,
  get: get,
  snapshot: snapshot,
  destroy: destroy,
  getRecursive: getRecursive,
  getClones: getClones,
  getSnapshots: getSnapshots,
  setProp: setProp,
  receiveStream: receiveStream,
  sendStream: sendStream,
  spawnReceiveStream: spawnReceiveStream,
  rename: rename,
  listPool: listPool,
  getPool: getPool
};
