/*
 
# SmartOS Dataset Library

This library is specifically written to manage and manipulate
datasets in SmartOS. A dataset is a binary blob which is 
presented to a virtual machine as a local storage volume;
The dataset usually contains an operating system.

When a dataset is installed, it is downloaded from the appropriate
server or service and piped to zfs. custom properties are set. Those
custom properties include "dsadm:urn" and "dsasdm:uuid", which
represent the urn and uuid of the dataset that was installed.
This can be used to identify the dataset if the dsadm database is
missing. 

The database is a collection of manifests stored in /var/lib/dsadm
Those manifests are saved in order to be able to have local information
about the dataset, and its requirements.

If at any time the database is destroyed, you can try and run the
repair.sh tool which will - in a rather brutish manner - attempt
to rebuild the database by comparing the uuids of existing datasets 
with the ones available in dsapi.

Datasets may be destroyed only if they do not have any children.
Children includes 'snapshots' and 'clones' of those snapshots.
If any children other than the snapshot of the dataset itself
exists, then you will not be able to remove the dataset from the 
compute node. 


*/

var assert = require('assert');
var url = require('url');
var fs = require('fs');
var path = require('path');
var spawn = require('child_process').spawn;
var http = require('http');
var https = require('https');
var dns = require('dns');
var zfs = require('./zfs');
var common = require('./common'); 
var log = common.log;
var db = require('./db');

ZPOOL_NAME = 'zones'; 
DSAPI_URL  = 'https://datasets.joyent.com/datasets/'; // need trailing slash
DB_CACHE   = '/var/db/dsadm/dscache.json';
DB_SOURCES = '/var/db/dsadm/sources.list';

CURL  = '/usr/bin/curl';
BZIP2 = '/usr/bin/bzip2';
GZIP  = '/usr/bin/gzip';
MOUNT = '/usr/sbin/mount';


var FILTER_FIELDS = [
  'name',
  'version',
  'uuid',
  'urn',
  'type',
  'description',
  'os',
  'published_at',
  'creator_uuid',
  'creator_name',
  'owner_uuid'
];


_isUuid = function(obj) {
  var uuidReg = /[a-z0-9]{8}-[a-z0-9]{4}-[a-z0-9]{4}-[a-z0-9]{4}-[a-z0-9]{12}/;
  if (typeof(obj) === 'string') {
    return (uuidReg.test(obj));
  } 
  return false;
}

_isUrn = function(obj) {
  var urnReg = /[a-z0-9-_]+:[a-z0-9]+:[a-z0-9._-]+:[a-z0-9._-]+/;
  if (typeof(obj) === 'string') {
    return (urnReg.test(obj));
  }
  return false;
}

_isUrl = function(obj) {
  if (typeof(obj) === 'string') {
    var o = url.parse(obj);
    if (o.host && o.protocol && o.pathname) 
      return true;
  }
  return false;
};

_curlHost = function(options) {
  if (typeof(options) !== 'object') {
    throw new TypeError("options must be an object");
  }

  var auth = '';
  if (options.auth) auth = options.auth + "@"
  return options.protocol + '//' + auth + options.host + options.path;
}

datasetExists = function(uuid, callback) {
  db.load(uuid, function(err, record) {
    if (err || record.uuid == undefined) { 
      callback(false);
    }
    else {
      callback(true);
    }
  })
}

httpOptions = function(manifestId, callback) {
  var opts;
  
  
  if (!manifestId) {
    opts = url.parse(DSAPI_URL);
  }
  else if (_isUrl(manifestId)) {
    opts = url.parse(manifestId);
  }
  else if (_isUuid(manifestId)) {
    opts = url.parse(DSAPI_URL + manifestId);
  } 
  else {
    throw new Error("options requires a URL or UUID");
  }
  
  opts.headers = {
    'accept': 'application/json'
  };
  
  // nodev4 fixup (url and http client reqs dont match)
  if (opts.pathname) {
    opts.path = opts.pathname; 
    opts.pathname = undefined;
  }
  if (opts.auth) {
  	var s = opts.host.split(/@/);
  	opts.host = s[s.length-1];
  	var auth = 'Basic ' + new Buffer(opts.auth).toString('base64');
  	opts.headers['Authorization'] = auth;
  }
 
  // SmartOS DNS is disabled by default. We rely on node to
  // resolve the host for us.
  dns.resolve4(opts.hostname, function(err, addresses) {
    if (err) throw new Error("could not resolve host: " + opts.hostname);
    // pick one at random?
    opts.host = addresses[0]; 
    callback(opts);
  });

}

httpClient = function(options) {
  var client;
  switch (options.protocol) {
    case 'https:':
      client = https;
      break;
    case 'http:':
      client = http;
      break;
  }
  return client;
}


// Todo just replace this with Array.filter and create
// a list of filter functions (ele, idx, arr)
filterResults = function(fields, toFilter) {
  var filterOn = FILTER_FIELDS;
  var results = [];

  for (var i=0; i<toFilter.length; i++) {
    var item = toFilter[i];
    var r = {};
    for (var f=0; f<filterOn.length; f++) {
      r[filterOn[f]] = item[filterOn[f]];
    }
    results.push(r);
  }

  return results;
}

var loadSources = function (sourcefile) {
  // config only supports comments starting with '#',
  // whitspace then a '#', or empty lines
  // '#' characters in the URL are not supported either

  if (path.existsSync(sourcefile) == false) {
    return false;
  }

  log.debug("using sources file %s", sourcefile);
  var sources = fs.readFileSync(sourcefile, 'utf8');
  var lines = sources.split(/\n/); 
  var results = [];

  for (var i=0; i<lines.length; i++) {
    var line = lines[i];
    if (line.match(/^\s*[$#]/) || line === '' ) continue;
    if (_isURL(line)) results.push(line);
  }
 
  return results; 
}

var loadCache = function (cachefile) {
  if (path.existsSync(cachefile) == false) {
    return false;
  }

  log.debug("loading cache file %s", cachefile);
  var rawcache = fs.readFileSync(cachefile, 'utf8');
  var cache = JSON.parse(rawcache); 
  return cache;
}

var cacheList = function (callback) {
  var cache = loadCache(DB_CACHE);
  if (!cache) {
    return callback("Cache file couldn't be loaded. Try 'dsadm update' first", null);
  }

  var results = filterResults(null, loadCache(DB_CACHE));
  callback(null, results);
}

var cacheUpdate = function (callback) {

  var sources = loadSources(DB_SOURCES);
  if (!sources) {
    return callback("couldn't load source file " + DB_SOURCES, null);
  }

  var counter = sources.length;
  var cache = [];
  
  var next = function () {
    --counter || complete();
  }

  var complete = function(err) {
    if (err) callback("error downloading image list", null)
    fs.writeFileSync(DB_CACHE, JSON.stringify(cache), 'utf8');
    console.log("done");
  }

  log.info("updating local images database...");
  for (var i=0; i<sources.length; i++) {

    var source = sources[i];
    var options = url.parse(sources[i]);
    /*The extra lambda around the funcion call of dns.resolve4
      Is rather ugly but it is required to solve a scoping problem.
      Without it options and source will 'run away' through the 
      for loop and all callbacks end up with the same options and
      sourece (the laste one). This problem is not visible with one
      entry only but gets triggered if there are two or more.
      A simplyfied version of this problem can be seen here:
      https://gist.github.com/2595753
     */
    (function(options,source) {
      // SmartOS DNS is disabled by default
      dns.resolve4(options.hostname, function(err, addresses) {
        var body = "";
        if (err) callback("could not resolve host: " + opts.hostname);

        options.host = addresses[0]; 
        delete (options.hostname); //XXX 

        var client = httpClient(options);
      
        console.log("Get %s...", source);
      
        client.get(options, function (res) {
        
          res.on('data', function (chunk) {
            body += chunk.toString();
          });

          res.on('end', function () {
            var dsdb = JSON.parse(body);
            for (var d=0; d<dsdb.length; d++) {
              // set url property so relpaths work later
              dsdb[d]['_url'] = source;
              cache.push(dsdb[d]);
            }

            next();
          });
        
        }); 
      });
    })(options, source);
  }

}

// returns manifest specified by uuid
var show = function(uuid, callback) {
  var cache = loadCache(DB_CACHE);
  if (!cache) {
    return callback("error loading cache", null);
  }

  var result = null;
  for (var i=0; i<cache.length; i++) {
    if ( cache[i].uuid == uuid ) {
      result = cache[i];
      break;
    }
  }
  
  if (result) {
    callback(null, result);
  }
  else {
    callback("not found", null);
  } 
}

var dump = function(name, callback) {
  assert.ok(name);
  assert.ok(callback);

  var result = {
    volume: {},
    children: {
      snapshots: [],
      clones: []
    },
    manifest: {}
  };
    
  onLoad = function(err, manifest) {
    if (err) return callback(err, null);
 
    result.manifest = manifest;
    var _name = ZPOOL_NAME + '/' + name;
 
    zfs.getRecursive(_name, function(err, snapshots) {

      var error;
      var n;
      
      result.volume = snapshots.shift();
      result.children.snapshots = snapshots;
      n = snapshots.length; 
      
      var cb_n = function(next) {
        return function() {
          --n || next(error, result);
        }
      };


      zfs.list(null, function (err, list) {
        if (err) return callback(err, null);
       
        var snapNames = snapshots.map(function(val) {
          return val.name;
        });
        
        for (i in list) {
          var d = list[i];
          if (snapNames.indexOf(d.origin) >= 0) {
            result.children.clones.push(d);
          }
        } 
        callback(error, result);
      });

    });

  };

  datasetExists(name, function(exists) {
    if (!exists) {
      callback("dataset not found", null);
    }
    else {
      db.load(name, onLoad); 
    }
  });

}

var spawnInflater = function(type) {
  assert.ok(type);

  var inflater = null;
  var args = ['-cdfq'];

  switch(type) {
    case 'gz':
      inflater = spawn(GZIP, args); 
      break;
    case 'bz2':
      inflater = spawn(BZIP2, args);
      break;
    default:
      throw new Error("inflater type must be one of 'gz' or 'bz2'");
      break;
  }
 
  return inflater; 
}

var importLocal = function(mfile, filename, callback) {
  assert.ok(mfile);
  assert.ok(filename);
  assert.ok(callback);

  var uuid, inflater, manifest, valid;
  
  manifest = JSON.parse(fs.readFileSync(mfile, 'utf8'));
  valid = db.validateManifest(manifest);
  if (valid != true) return callback(valid);
  
  uuid = manifest.uuid;

  datasetExists(uuid, function(exists) {
    if (exists) {
      callback("dataset already installed");
    }
    else {
      var dsfile = manifest.files[0];
      log.debug("%s urn: %s",               uuid, manifest.urn);
      log.debug("%s size (bytes compressed): %s",  uuid, dsfile.size);
      log.debug("%s checksum: (sha1) %s",   uuid, dsfile.sha1);
      log.debug("%s path: %s",              uuid, dsfile.path);

      zfs.getPool(ZPOOL_NAME, function(err, pool) {
        var volname = ZPOOL_NAME + '/' + uuid;
        var volnameTemp = volname + '-partial';
						
        localImport = function() {
          if ( /\.gz$/.test(dsfile.path) ) {
            inflater = spawnInflater('gz');
          }
          else if (/\.bz2$/.test(dsfile.path)) {
            inflater = spawnInflater('bz2');
          }

          if (inflater) {
            log.debug("%s requires inflate stream", uuid);

            inflater.stderr.on('data', function(chunk) {
              log.err("%s got inflater error: %s", uuid, chunk.toString());
            }); 

            inflater.stdout.pipe(zfsIn.stdin);
            var rs = fs.createReadStream(filename, {end: false});
            rs.pipe(inflater.stdin);

          } 
          else {
            var rs = fs.createReadStream(filename, {end: false});
            rs.pipe(zfsIn.stdin);
          }

        }
        
        log.info("%s doesnt exist. continuing with install", uuid);
        log.debug("%s zpool has %sMB free", ZPOOL_NAME, pool.free);
        log.debug("%s importing to %s", uuid, volname);
        
        zfsIn = zfs.spawnReceiveStream(volnameTemp);
        localImport();

        zfsIn.on('exit', function(code, signal) {
          if (code != 0) {
            log.debug("%s zfs recieve exited non-zero: %s", uuid, code);
            return callback("zfs receive exited non zero: " + code, uuid);
          } 
          else {
            onImport(manifest, callback);
          }
        });
        
    
      });
    }
  }); 
}

var onImport = function(manifest, callback) {
  var uuid = manifest.uuid;
  var volname = ZPOOL_NAME + '/' + uuid; 

  zfs.rename(volname + '-partial', volname, function(err) {
    if (err) return callback(err, uuid);
    zfs.setProp(volname, "dsadm:uuid", uuid, function(err) {
      if (err) return callback(err, uuid);
      zfs.setProp(volname, "dsadm:urn", manifest.urn, function(err) {
        if (err) return callback(err, uuid);
        db.save(manifest, function(err) {
          if (err) return callback(err);
          log.info("%s successfully installed",  uuid);
          callback(err, uuid);
        });  
      });
    });
  });  
  
}


var importRemote = function(uuid, callback) {
  assert.ok(uuid);
  assert.ok(callback);

  show(uuid, function(error, manifest) {
    if (error) 
      return callback(error);
 
    var inflater, dsfile, _url;

    datasetExists(uuid, function(exists) {
      if (exists) 
        return callback("dataset already installed");

			// The file to download is comprised of:
			// https://host/datasets/:uuid/:dsfile.path  
			dsfile = manifest.files[0];
			
			log.debug("%s urn: %s",               uuid, manifest.urn);
			log.debug("%s size (bytes compressed): %s",  uuid, dsfile.size);
			log.debug("%s checksum: (sha1) %s",   uuid, dsfile.sha1);
			log.debug("%s path: %s",              uuid, dsfile.path);

			zfs.getPool(ZPOOL_NAME, function(err, pool) {
        var curl, zfsIn;
        var args = ['--insecure'];
        
        var volname = ZPOOL_NAME + '/' + uuid; 
        var volnameTemp = volname + '-partial'; 
     
        downloadDataset = function() {
          if ( /\.gz$/.test(dsfile.path) ) {
            inflater = spawnInflater('gz');
          }
          else if (/\.bz2$/.test(dsfile.path)) {
            inflater = spawnInflater('bz2');
          }

          if (inflater) {
            log.debug("%s requires inflate stream", uuid);

            inflater.stderr.on('data', function(chunk) {
              log.err("%s got inflater error: %s", uuid, chunk.toString());
            }); 

            inflater.stdout.pipe(zfsIn.stdin);
            curl = spawn(CURL, args);
            curl.stdout.pipe(inflater.stdin);

          } 
          else {
            //args.push(_curlHost(options)); 
            curl = spawn(CURL, args);
            curl.stdout.pipe(zfsIn.stdin);
          }

        }
        
        zfsIn = zfs.spawnReceiveStream(volnameTemp);
        
        zfsIn.on('exit', function(code, signal) {
          if (code != 0) {
            log.debug("%s zfs recieve exited non-zero: %s", uuid, code);
            return callback("zfs receive exited non zero: " + code, uuid);
          } 
          else {
            onImport(manifest, callback);
          }
        });
        
        var options = url.parse(manifest._url);
        log.info("%s doesnt exist. continuing with install", uuid);
        log.debug("%s zpool has %sMB free", ZPOOL_NAME, pool.free);
        log.debug("%s importing to %s", uuid, volname);
        log.debug("%s downloading file from: %s",  uuid, options.hostname);

        // SmartOS DNS is disabled by default
        dns.resolve4(options.hostname, function(err, addresses) {
          if (err) callback("could not resolve host: " + opts.hostname);
          options.host = addresses[0]; 
          delete (options.hostname); //XXX 
          options.path = path.join(options.path, uuid, dsfile.path);
          args.push(_curlHost(options)); 
          downloadDataset();
        });
        

			});

    });
  });
}

destroyDataset = function(name, callback) {
  assert.ok(name);
  assert.ok(callback);

  dump(name, function(err, dump) {
    if (err) return callback(err);
    log.debug("%s checking number of children", name);
    var numClones = dump.children.clones.length;

    if (numClones > 0) {
      log.debug("%s has %s dependent clones. cannot destroy", name, numClones);
      return callback("dataset has children. cannot destroy");
    } 
    else {
      log.info("destroying dataset %s", name);
      zfs.destroy(dump.volume.name, {recursive: true}, function(err) {
        log.debug("%s destroying zfs volume", name);
        if (err) return callback(err);
        db.destroy(name, function(err) {
          log.debug("%s removing database record", name);
          callback(err);
        });
      });
    }
  });

};

module.exports = {
  importRemote: importRemote,
  importLocal: importLocal,
  destroyDataset: destroyDataset,
  listLocal: db.all,
  dump: dump,
  cacheUpdate: cacheUpdate,
  cacheList: cacheList,
  show: show
}


